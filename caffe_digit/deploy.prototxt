name: "LeNet"
layer {
  name: "mnist"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 64
      dim: 3
      dim: 28
      dim: 28
    }
  }
}

layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1   # 权值学习速率倍乘因子，1表示保持与全局一致
  }
  param {
    lr_mult: 2   # bias学习速率倍乘因子，是全局参数的 2 倍
  }
  convolution_param {  # 卷积参数
    num_output: 20     # 输出特征 feature map 数目是 20
    kernel_size: 5     # 卷积核尺寸5*5
    stride: 1          # 步长1
    weight_filler {    # 权值使用xavier填充器（这是啥？？）
      type: "xavier"
    }
    bias_filler {      # bias使用常数填充，默认0
      type: "constant"
    }
  }
}

layer {               # 定义下采样层，输入 bolb 为 covn1 输出 pool1
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {   # 使用最大值下采样方法
    pool: MAX
    kernel_size: 2  # 下采样窗口尺寸2*2
    stride: 2       # 步长2
  }
}

layer {            # 新的卷积层covn2
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}

layer {        # 下采样层
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

layer {        #  全连接层
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500            # 输出元素个数500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}

layer {      # 非线性层，激活函数
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}

layer {              # 新的全连接层
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}

layer {                 # 损失层，
  name: "prob"
  type: "Softmax"
  bottom: "ip2"
  top: "prob"
}
